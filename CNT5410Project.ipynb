{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# CNT5410Project code, author: Siqi Dai"
      ],
      "metadata": {
        "id": "I8fUc4aT0wsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchcsprng\n",
        "!pip install opacus"
      ],
      "metadata": {
        "id": "GLgzYWn-s6W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er3T0HAh0CQb"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "import torch \n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as dsets \n",
        "import torchvision.transforms as transforms\n",
        "random_seed = 6\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "batch_size = 200\n",
        "# MNIST dataset\n",
        "train_dataset = dsets.MNIST(root='./pymnist', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = dsets.MNIST(root='./pymnist', train=False, transform=transforms.ToTensor(), download=True)\n",
        "# load_data\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# original_data\n",
        "print(\"train_data:\", train_dataset.train_data.size())\n",
        "print(\"train_labels:\", train_dataset.train_labels.size())\n",
        "print(\"test_data:\", test_dataset.test_data.size())\n",
        "print(\"test_labels:\", test_dataset.test_labels.size())\n",
        "# shuffle batch_size data\n",
        "print(\"batch_size:\", train_loader.batch_size)\n",
        "print(\"load_train_data:\", train_loader.dataset.train_data.shape)\n",
        "print(\"load_train_labels:\", train_loader.dataset.train_labels.shape)\n"
      ],
      "metadata": {
        "id": "VJjRYfix4qnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target model, only has two layers\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(3, 16, 5)\n",
        "        self.fc1 = nn.Linear(256, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 256)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "soWSifkk4t3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  model with noise\n",
        "from opacus import PrivacyEngine\n",
        "# import torchcsprng as prng\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "privacy_engine = PrivacyEngine(\n",
        "            secure_mode=None,\n",
        "        )\n",
        "dpnet = Net()\n",
        "learning_rate = 1e-1\n",
        "\n",
        "optimizer = torch.optim.SGD(dpnet.parameters(), lr=learning_rate)\n",
        "\n",
        "dpnet, optimizer, train_loader = privacy_engine.make_private(\n",
        "            module=dpnet,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=train_loader,\n",
        "            noise_multiplier=4, # noise multiplier\n",
        "            max_grad_norm=10.0,\n",
        "            clipping=\"flat\",\n",
        "        )\n",
        "\n",
        "\n",
        "for epoch in range(5):\n",
        "    print(\"current epoch = {}\".format(epoch))\n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        # print(images.shape)\n",
        "        # images = (images.view(-1, 28*28))\n",
        "        labels = (labels)\n",
        "        # print(labels)\n",
        "\n",
        "        outputs = dpnet(images)\n",
        "        # print(outputs)\n",
        "        # print(labels)\n",
        "        loss = criterion(outputs, labels)  # calculate loss\n",
        "        optimizer.zero_grad()  # clear net state before backward\n",
        "        loss.backward()       \n",
        "        optimizer.step()   # update parameters\n",
        "\n",
        "        if i%5000 == 0:\n",
        "            print(\"current loss = %.5f\" %loss.item())\n",
        "print(\"finished training\")"
      ],
      "metadata": {
        "id": "A9QC9k4nrX0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(dpnet.state_dict(), \"/content/withDP.pth\") # save model with noise\n"
      ],
      "metadata": {
        "id": "cPrPrNmXu0_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target model\n",
        "net = Net()\n",
        "print(net)\n",
        "learning_rate = 1e-1\n",
        "num_epoches = 5\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "for epoch in range(num_epoches):\n",
        "    print(\"current epoch = {}\".format(epoch))\n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        # print(images.shape)\n",
        "        # images = (images.view(-1, 28*28))\n",
        "        labels = (labels)\n",
        "        # print(labels)\n",
        "\n",
        "        outputs = net(images)\n",
        "        # print(outputs)\n",
        "        # print(labels)\n",
        "        loss = criterion(outputs, labels)  # calculate loss\n",
        "        optimizer.zero_grad()  # clear net state before backward\n",
        "        loss.backward()       \n",
        "        optimizer.step()   # update parameters\n",
        "\n",
        "        if i%5000 == 0:\n",
        "            print(\"current loss = %.5f\" %loss.item())\n",
        "print(\"finished training\")\n"
      ],
      "metadata": {
        "id": "7v5IPmhp48mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"/content/shadow.pth\") # save model with no noise\n"
      ],
      "metadata": {
        "id": "XPYNs9x3exZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "for images, labels in test_loader:\n",
        "    # images = (images.view(-1, 28*28))\n",
        "    labels = (labels)\n",
        "    outputs = net(images)\n",
        "\n",
        "    _,predicts = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicts == labels).sum()\n",
        "print(\"Accuracy = %.2f\" %(100*correct/total))\n"
      ],
      "metadata": {
        "id": "GGuBxPtn5l_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# thieft model, has three layers\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 3)\n",
        "        self.pool = nn.MaxPool2d(1, 1)\n",
        "        self.conv2 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(6400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        # print(x.shape)\n",
        "        x = x.view(-1, 6400)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HGkrYEoL_pci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test similarity \n",
        "def testd(model,shadow,test_loader):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in test_loader:\n",
        "        # images = (images.view(-1, 28*28))\n",
        "        images = images.to(torch.float32)\n",
        "        labels2 = shadow(images)\n",
        "        _, predicts2 = torch.max(labels2.data, 1)\n",
        "\n",
        "\n",
        "        labels = (labels)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _,predicts = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicts == predicts2).sum()\n",
        "    print(\"Accuracy = %.2f\" %(100*correct/total))"
      ],
      "metadata": {
        "id": "E1pVElVJyW1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test accuracy \n",
        "def testr(model,test_loader):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for images, labels in test_loader:\n",
        "      # images = (images.view(-1, 28*28))\n",
        "      images = images.to(torch.float32)\n",
        "\n",
        "      labels = (labels)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _,predicts = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicts == labels).sum()\n",
        "  print(\"Accuracy = %.2f\" %(100*correct/total))\n",
        "\n",
        "\n",
        "#train new model in accordance of the shadow model\n",
        "def shadow(shadownet):\n",
        "    model = Model()\n",
        "    print(model)\n",
        "    learning_rate2 = 1e-1\n",
        "    num_epoches2 = 3\n",
        "    criterion2 = nn.CrossEntropyLoss()\n",
        "    optimizer2 = torch.optim.SGD(model.parameters(), lr=learning_rate2)\n",
        "    # train_dataset=my_trainData_Set()\n",
        "    # test_dataset=my_testData_Set()\n",
        "\n",
        "    train_dataset = dsets.MNIST(root='./pymnist', train=True, transform=transforms.ToTensor(), download=True)\n",
        "    test_dataset = dsets.MNIST(root='./pymnist', train=False, transform=transforms.ToTensor(), download=True)\n",
        "    train_loader2 = DataLoader(dataset=train_dataset, batch_size=200, shuffle=True)\n",
        "    test_loader2 = DataLoader(dataset=test_dataset, batch_size=200, shuffle=False)\n",
        "    newLabel = []\n",
        "\n",
        "    # shadow = Net()\n",
        "    # shadow.load_state_dict(torch.load('/content/shadow.pth'))\n",
        "    # shadow.eval()\n",
        "    print(\"accuracy of thief model after training\")\n",
        "    testr(shadownet,test_loader2)\n",
        "    print(\"accuracy of thief model before training\")\n",
        "\n",
        "    testr(model,test_loader2)\n",
        "    print(\"similarity:\")\n",
        "    testd(model,shadownet,test_loader2)\n",
        "    for epoch in range(num_epoches2):\n",
        "        print(\"current epoch = {}\".format(epoch))\n",
        "        for i, (images, labels) in enumerate(train_loader2):\n",
        "            # print(images.shape)\n",
        "            # images = (images.view(-1, 28*28))\n",
        "            # labels = (labels)\n",
        "            images = images.to(torch.float32)\n",
        "\n",
        "            labels2 = shadownet(images)\n",
        "\n",
        "            # print(labels)\n",
        "            # labels3=labels2.detach().numpy()\n",
        "            # newLabel.append(labels3)\n",
        "            # print(predicts)\n",
        "\n",
        "            # print(newLabel)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicts = torch.max(labels2.data, 1)\n",
        "\n",
        "            # print(outputs.shape)\n",
        "            # print(predicts.shape)\n",
        "            # print(predicts)\n",
        "            # print(\"**\")\n",
        "            # print(labels)\n",
        "            # print(\"--\")\n",
        "\n",
        "            loss2 = criterion2(outputs, predicts)  # calculate loss)\n",
        "            optimizer2.zero_grad()  # clear net state before backward\n",
        "            loss2.backward()\n",
        "            optimizer2.step()  # update parameters\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                print(\"current loss = %.5f\" % loss2.item())\n",
        "    print(\"finished training, thief model\")\n",
        "    testr(model,test_loader2)\n",
        "    print(\"similarity:\")\n",
        "    testd(model,shadownet,test_loader2)\n",
        "    "
      ],
      "metadata": {
        "id": "GsH0qQfyaHyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to test accuracy\n",
        "def test(model,test_loader):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for images, labels in test_loader:\n",
        "      # images = (images.view(-1, 28*28))\n",
        "      labels = (labels)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _,predicts = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicts == labels).sum()\n",
        "  print(\"Accuracy = %.2f\" %(100*correct/total))\n"
      ],
      "metadata": {
        "id": "mG8sR_r1opGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow(net)"
      ],
      "metadata": {
        "id": "kkGmv2FcMtV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow(dpnet)\n"
      ],
      "metadata": {
        "id": "Uw_Ky_TnhM0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jG77sf7qd4dW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}